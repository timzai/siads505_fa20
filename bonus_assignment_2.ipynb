{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An attempt at a more formal grammar\n",
    "\n",
    "```\n",
    "function_to_call  ::= <wordcharacters>\n",
    "parameters        ::= \"\" | \"(\" ( wordcharacters | number ) \")\"\n",
    "as_name           ::= \"\" | \"as\" <whitespace> <wordcharacters>\n",
    "column_name       ::= as_name | function_to_call\n",
    "reference         ::= \"\" |  \"[\" number \"]\"\n",
    "unique_mark       ::= \"\" | \"*\"\n",
    "column_definition ::= <function_to_call> <parameters> <whitespace> \\\n",
    "                      <as_name> <whitespace> <reference> <unique_mark>\n",
    "df_size           ::= \"\" |  \"[\" integer \"]\"\n",
    "df_sep            ::= \"--\" (\"-\"*)\n",
    "df_definition     ::= <wordcharacters> <df_size> <newline> <df_sep> <newline> \\\n",
    "                      (<column_definition>*) <newline> <newline>\n",
    "language_spec     ::= <def_definition>*\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Config for generator\n",
    "# Please tweak these numbers sensibly, keeping in mind unique faker values and reference linking\n",
    "DEFAULT_DF_SIZE = 99   # default number of rows per DataFrame\n",
    "MAX_REPEATS = 4        # maximum number of times a reference can repeat (1 = repeated at most once)\n",
    "ORPHANED_UNIQUES = 0.2 # % of uniques references which won't be used \n",
    "IS_DEBUG = True        # debug flag for a few print statements.  not sure if and how __debug__ should be used instead?\n",
    "# Global variables\n",
    "reference_dict = {} # persistent reference for the reference columns, dict of sets\n",
    "fake = Faker()\n",
    "\n",
    "# Helper functions for casting parameters to int, float or string\n",
    "def cast_parameter(x):\n",
    "    if x is None:\n",
    "        return x\n",
    "    elif type(x) != str:\n",
    "        raise ValueError('Input must be a string or None')\n",
    "    try:\n",
    "        a = float(x)\n",
    "        b = int(a)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        if a == b:\n",
    "            return b\n",
    "    try:\n",
    "        a = float(x)\n",
    "    except ValueError:\n",
    "        return x\n",
    "    else:\n",
    "        return a\n",
    "    \n",
    "def dprint(s):\n",
    "    if IS_DEBUG:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generate a singular value based on the Faker function and reference used\n",
    "# Uniqueness is checked against the set \"set_for_uniqueness\", a local reference for the caller is needed\n",
    "# Pass None to set_for_uniqueness for no uniqueness requirement\n",
    "\n",
    "def gen_data(_, function_name,parameter,set_for_uniqueness):\n",
    "    # QUESTION: not sure if passing by set() by reference for set_for_uniqueness will mess up by panda's\n",
    "    #           concurrency. It SEEMS OK, but have not tested rigorously\n",
    "    # TODO:     parameter currently only takes 1 variable, need to convert to support multiple?\n",
    "    # TODO:     For some function_name like first_name, we can directly get the Provider list of possible\n",
    "    #           values and get a subset from it rather than repeatedly generating them\n",
    "    #               from faker.providers.person.en import Provider\n",
    "    #               set(Provider.first_names)\n",
    "    func = getattr(fake, function_name)\n",
    "    parameter = cast_parameter(parameter)\n",
    "    while(True):\n",
    "        value = func() if parameter is None else func(parameter)\n",
    "        if type(set_for_uniqueness) is set:\n",
    "            if value not in set_for_uniqueness:\n",
    "                set_for_uniqueness.add(value)\n",
    "                return value\n",
    "        else:\n",
    "            return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates data specifically for reference columns since the data needs to be shared amongst DataFrames\n",
    "\n",
    "def get_reference_column_data(reference_key, function_name,parameter,is_unique, count):\n",
    "    # ASSUMPTION: assuming that function_name and parameter for each reference is configured the same way\n",
    "    # first generate unique set of data if it doesn't already exist\n",
    "    if reference_key not in reference_dict.keys():\n",
    "        # FIXME: need to generate unique reference key first.\n",
    "        new_data = set()\n",
    "        while(len(new_data)<count):\n",
    "            new_data.add(gen_data(None, function_name,parameter,new_data))\n",
    "        reference_dict[reference_key] = new_data\n",
    "\n",
    "    if is_unique:\n",
    "        # if we are just looking for the unique data, we can returned the shuffled set\n",
    "        return random.sample(reference_dict[reference_key], len(reference_dict[reference_key]))\n",
    "    else:\n",
    "        # sample items to exclude some reference values\n",
    "        values = random.sample(reference_dict[reference_key], int(count*(1-ORPHANED_UNIQUES)))\n",
    "        # return sampled items (so they appear at least once) and fill the rest with the same sampled items\n",
    "        # based on the MAX_REPEATS configuration\n",
    "        return values + random.sample(values * (MAX_REPEATS-1),count - len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def fakedata(line, cell):\n",
    "\n",
    "    # We can probably do some checking here, such as:\n",
    "    # * no dataframes with same name\n",
    "    # * no duplicate names for columns with same name\n",
    "    \n",
    "    # Step 1, we parse the input into 2 separate dataframes\n",
    "    # dataframe_size contains the size for each dataframe\n",
    "    # dataframe_col_def contains column definitions of each dataframe\n",
    "    dataframe_size = pd.DataFrame(columns=['name', 'size'])\n",
    "    dataframe_size.set_index('name', inplace=True)\n",
    "    dataframe_col_def = pd.DataFrame(columns=['df_name', 'col_name', 'function', 'parameter', 'as_name', 'reference', 'unique_mark'])\n",
    "    dataframe_col_def.set_index(['df_name','col_name'], inplace=True)\n",
    "\n",
    "    # we split the dataframes out to process them one at a time\n",
    "    regex = re.compile(r'(?P<df_name>[\\w]+)(?: \\[(?P<df_size>\\d+)\\])?(?:\\n-+\\n)(?P<df_def>(?:.+\\n?)+)')\n",
    "    \n",
    "    for dfdict in [m.groupdict() for m in regex.finditer(cell.strip())]:\n",
    "        df_name = dfdict['df_name']\n",
    "        df_size = int(dfdict['df_size']) if dfdict['df_size'] is not None else DEFAULT_DF_SIZE\n",
    "        definitions = dfdict['df_def'].strip().split('\\n')\n",
    "\n",
    "        # we can check that there are no duplicated dataframe names\n",
    "        assert df_name not in dataframe_size.index, \"DataFrames with duplicated names found: {}\".format(df_name)\n",
    "        dataframe_size.loc[df_name] = [df_size]\n",
    "        \n",
    "        # break down each column of the DataFrame based on provided definitions\n",
    "        for d in definitions:\n",
    "            dpattern = r\"^(?P<function>\\w+)(?:(?:\\((?P<parameter>[-+]?\\d*\\.?\\d+|\\w+)\\))?)(?: as (?P<as_name>\\w*))?(?: \\[(?P<reference>\\d+)\\])?(?P<unique_mark>\\*)?$\"\n",
    "            dmatch = re.search(dpattern,d).groupdict()\n",
    "            col_name = dmatch['as_name'] if dmatch['as_name'] is not None else dmatch['function']\n",
    "        \n",
    "            # we can check that there are no duplicated dataframe names\n",
    "            assert (df_name, col_name) not in dataframe_col_def.index, \"Columns with duplicated names found in DataFrame \\\"{}\\\": {}\".format(df_name, col_name)\n",
    "            dataframe_col_def.loc[(df_name, col_name),dataframe_col_def.columns] = [dmatch['function'], dmatch['parameter'], dmatch['as_name'], dmatch['reference'], dmatch['unique_mark']]\n",
    "    \n",
    "    # we don't need as_name anymore since column names are set, so let's drop it\n",
    "    dataframe_col_def.drop(columns=['as_name'], inplace=True)\n",
    "\n",
    "    # These are the parsed input\n",
    "    print(dataframe_size)\n",
    "    print(dataframe_col_def)\n",
    "    \n",
    "    # Now let's create the dataframes!\n",
    "    \n",
    "    # Step 2, pre-generate all references first\n",
    "    # for each reference that has  a unique_mark, we generate the exact amount needed to fill its dataframe\n",
    "    # if no unique, just find the highest\n",
    "    \n",
    "    while(False):\n",
    "        # create DataFrame \n",
    "        df = pd.DataFrame(index=range(0,df_size), columns=column_info.keys())\n",
    "        \n",
    "        #populate each column with data\n",
    "        for k,v in column_info.items():\n",
    "            if v['reference'] is not None:\n",
    "                # this is a reference column, we need to reference our references of the reference\n",
    "                # since we're demonstrating One to Many\n",
    "                df[k] = get_reference_column_data(v['reference'],v['function'],v['parameter'],v['unique_mark'] is not None, df_size)\n",
    "            else:\n",
    "                df[k] = df[k].apply(gen_data, args=(v['function'],v['parameter'],None if v['unique_mark'] is None else set()))\n",
    "        \n",
    "        # assign the created DataFrame as a global variable using the provided name\n",
    "        globals()[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['persons', 'first_name'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-973a8deb6c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fakedata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'persons [20]\\n-------\\nfirst_name\\nlast_name*\\nphone_number\\nrandom_number(5) as customer_number [1]*\\n\\npurchases [20]\\n---------\\nisbn10\\ncredit_card_full\\nrandom_number(3) as price\\nrandom_number(5) as customer_number [1]\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d0f9ce0fda2f>\u001b[0m in \u001b[0;36mfakedata\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# we can check that there are no duplicated dataframe names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframe_col_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Columns with duplicated names found in DataFrame \\\"{}\\\": {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mdataframe_col_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataframe_col_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'as_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_mark'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# we don't need as_name anymore since column names are set, so let's drop it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key, is_setter)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, key, axis, is_setter)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/siads-generic/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['persons', 'first_name'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "%%fakedata\n",
    "persons [20]\n",
    "-------\n",
    "first_name\n",
    "last_name*\n",
    "phone_number\n",
    "random_number(5) as customer_number [1]*\n",
    "\n",
    "purchases [20]\n",
    "---------\n",
    "isbn10\n",
    "credit_card_full\n",
    "random_number(3) as price\n",
    "random_number(5) as customer_number [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats for purchases['customer_number'] reference values\n",
    "# how many times distribution of number of times each customer_number appeared\n",
    "purchases['customer_number'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing my cast_parameter() helper function\n",
    "# l = [\"-1\",\"12313\",\"-1.0.0\",\"1.546\",\"-.4\",\"+31\",\"+.7\",\"abc123\",\"d7f8g8h8jh\",\"1e2\",\"-6e-3\",\"\", None]\n",
    "# for v in l:\n",
    "#     a = cast_parameter(v)\n",
    "#     print(\"{} value: [{}]\".format(type(a),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
